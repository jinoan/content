---
title: ë¹„ì „ê³µìë¥¼ ìœ„í•œ ì¸ê³µì§€ëŠ¥ ì…ë¬¸ê³¼ì • ë…¸íŠ¸ Day 3
date: 2021-05-03 13:57:00
category: ai_school
thumbnail: { thumbnailSrc }
draft: false
---



2019ë…„ ì–‘ì¬R&CDí˜ì‹ í—ˆë¸Œì—ì„œ ì§„í–‰ëœ **AI School 2ê¸° ë¹„ì „ê³µìë¥¼ ìœ„í•œ ì¸ê³µì§€ëŠ¥ ì…ë¬¸ê³¼ì •**ì—ì„œ í•„ê¸°í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ì²˜ìŒ 3ì¼ ë¶„ëŸ‰ë§Œ í•„ê¸°ê°€ ë³´ê´€ë˜ì–´ ìˆì–´ ê³µìœ í•©ë‹ˆë‹¤ğŸ™‚



---

> ê°•ì‚¬: ì´ìƒí›ˆ

### ë”¥ëŸ¬ë‹ ì´ì•¼ê¸°:

#### ë”¥ëŸ¬ë‹ í•™ìŠµì›ë¦¬ ë° í™˜ê²½

Contents

- Machine Learning Pipeline
- Neural Network ê¸°ë³¸ ì›ë¦¬
- Deep Neural Networkë¡œì˜ ë°œì „
- ë”¥ëŸ¬ë‹ì„ ìœ„í•œ í™˜ê²½



## Machine Learning Pipeline

- Data acquisition and understanding
  - Problem Definition
  - Data Collection
- Modeling
  - Feature Engineering
  - Model Selection
  - Optimization
  - Evaluation
- Deployment
  - Containers
  - Reporting
  - Applications
  - Databases



### Feature Engineering

<center>
    <b>ë¹„ì •ì œ ë°ì´í„°</b>: ë¹„ì •ì œ ë°ì´í„°ëŠ” í”¼ì³ ë²¡í„° í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ ìˆì§€ ì•Šë‹¤.<br/>
    â†“<br/>
    <b>í”¼ì³ ì¶”ì¶œ</b><br/>
    â†“<br/>
    <b>í”¼ì³ ë²¡í„°</b>: ë¹„ì •ì œ ë°ì´í„°ì—ì„œ í”¼ì³ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ í”¼ì³ ì¶”ì¶œì´ë¼ í•¨.
</center>

ì˜ˆì‹œ)

```json
house_info : {
	num_rooms: 6
	num_bedrooms: 3
	street_name: "Shorebird Way"
	num_basement_rooms: -1
	...
}
```

ì´ëŸ¬í•œ Json í˜•ì‹ ë°ì´í„°ì—ì„œ street_name í”¼ì³ë¥¼ ì¶”ì¶œí•˜ì—¬ ì»´í“¨í„°ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ one-hot encoding í•  ìˆ˜ ìˆìŒ

```
street_name í”¼ì³ =
[0, 0, ..., 0, 1, 0, ..., 0]
V í¬ê¸°ëŠ” ê³ ìœ í•œ ê±°ë¦¬ ì´ë¦„ ìˆ˜
```



#### Feature Engineering ì‹œ ê³ ë¯¼í•´ì•¼ í•  ë¶€ë¶„

- ë°ì´í„°ì˜ í‘œí˜„ ë°©ì‹
  - ìŠ¤ì¹¼ë¼, ë²¡í„°, Space ë“±
- ë°ì´í„° ë³€í™˜
  - ì—°ì†í˜•? ë²”ì£¼í˜•?
  - ë°”ì´ë„ˆë¦¬?
  - Binning?
- í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„± ë“±
- one-hot encoding, digit recognition



### Model Selection

ì˜ˆì¸¡ëª¨ë¸ì´ ì‹¤ì œ í˜„ìƒì„ Underfitting ë˜ëŠ” Overfittingí•˜ì§€ ì•Šë„ë¡ ê³ ë ¤í•˜ì—¬ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í•œë‹¤.



#### Evaluationì„ ë” ì˜í•˜ê¸° ìœ„í•œ ë°©ë²•

ë°ì´í„°ë¥¼ train dataì™€ validation data, test dataë¡œ split í•˜ì—¬ ì‚¬ìš©

- train dataë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµ
- validation dataë¥¼ ì´ìš©í•˜ì—¬ hyperparameters ê²°ì •
- test dataë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ í‰ê°€



## Neural Network ê¸°ë³¸ ì›ë¦¬

### Single Layer Perceptron

![d03_01](assets/d03_01.png 'https://www.researchgate.net/profile/Pradeep_Singh22/publication/283339701/figure/fig2/AS:421642309509122@1477538768781/Single-Layer-Perceptron-Network-Multilayer-Perceptron-Network-These-type-of-feed-forward.png')
$$
y=
\begin{cases}
0,&\text{if}\quad x_1w_1+x_2w_2+\dots\leÎ¸
\\
1,&\text{otherwise}
\end{cases}
$$

```
x: ì…ë ¥ ì‹ í˜¸ (input)
y: ì¶œë ¥ ì‹ í˜¸ (output)
w: ê°€ì¤‘ì¹˜. ì…ë ¥ ì‹ í˜¸ë³„ ê³ ìœ ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ë‹¤.
Î¸: ì„ê³„ì¹˜(ê°’). ë‰´ëŸ°ì„ í™œì„±í™” ì‹œí‚¤ëŠ” í•œê³„
```



Single Layer Perceptronì€ XORê³¼ ê°™ì€ ë¬¸ì œë¥¼ í’€ ìˆ˜ ì—†ë‹¤ëŠ” í•œê³„ê°€ ìˆë‹¤.

![d03_02](assets/d03_02.png 'https://i.imgur.com/7oMCFHN.png')



### Multi Layer Perceptron

![d03_03](assets/d03_03.png 'http://i.imgur.com/Jfquh1M.png')

Digit Recognitionì˜ ê²½ìš°

- 784 Inputs
- $u_j=\sum w_{ij}x_i$
- $u'_k=\sum w'_{jk}u_j$
- 10 Outputs



### Propagation

- Forward propagation
  - input training dataë¡œë¶€í„° outputì„ ê³„ì‚°í•˜ê³ , ê° output neuronì—ì„œì˜ errorë¥¼ ê³„ì‚°
- Back propagation
  - output neuronì—ì„œ ê³„ì‚°ëœ errorë¥¼ ê° edgeë“¤ì˜ weightë¥¼ ì‚¬ìš©í•´ ë°”ë¡œ ì´ì „ layerì˜ neuronë“¤ì´ ì–¼ë§ˆë‚˜ errorì— ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ ê³„ì‚°

ì°¸ê³ : http://sanghyukchun.github.io/74/

Neural Networkì˜ í˜•íƒœì— ë”°ë¼ í•™ìŠµê³¼ì •ì„ ì‚´í´ë³¼ ìˆ˜ ìˆëŠ” ì‚¬ì´íŠ¸:
http://playground.tensorflow.org



### Gradient Descent (GD)

#### Gradient

- ê°€ì¥ ì í•©í•œ ëª¨ë¸ì€ ì˜¤ë¥˜ë¥¼ ìµœì†Œí™” í•˜ëŠ” likelihoodë¥¼ ìµœëŒ€í™” í•˜ëŠ” ê²ƒì´ë‹¤.

- Gradientë€ í•¨ìˆ˜ê°€ ê°€ì¥ ë¹ ë¥´ê²Œ ì¦ê°€í•  ìˆ˜ ìˆëŠ” ë°©í–¥ì„ ì˜ë¯¸(í¸ë¯¸ë¶„, ì  (x, f(x))ì—ì„œ í•¨ìˆ˜ì™€ ì ‘í•˜ëŠ” ì„ ì˜ ê¸°ìš¸ê¸°)

- Fê°€ ë‹¨ë³€ìˆ˜ í•¨ìˆ˜ì¸ ê²½ìš°, ì  xì—ì„œì˜ ë¯¸ë¶„ê°’ì€ xê°€ ì•„ì£¼ ì¡°ê¸ˆ ë³€í–ˆì„ ë–„ f(x)ì˜ ë³€í™”ëŸ‰ì„ ì˜ë¯¸

  ```
  def difference_quotient(f, x, h):
  	return (f(x + h) - f(x)) / h
  ```



#### Step size(learning rate)

- í•œë²ˆ í•™ìŠµí•  ë•Œ í•´ê°€ ì´ë™í•˜ëŠ” ê±°ë¦¬ì— ëŒ€í•œ ë¹„ìœ¨
- ì‹œê°„ì— ë”°ë¼ ì´ë™ê±°ë¦¬ ì¤„ì„
- ì´ë™í•  ë•Œë§ˆë‹¤ ëª©ì í•¨ìˆ˜ë¥¼ ìµœì†Œí™”



#### Optimization

- Local minimumì— ë¹ ì§€ì§€ ì•Šê³  global minimumì— ë„ë‹¬í•  ìˆ˜ ìˆë„ë¡ gradient descent algorithmì„ ì„ íƒí•˜ê³  learning rateë¥¼ ì¡°ì ˆí•´ì•¼ í•œë‹¤.

- gradient descent algorithmì˜ ì¢…ë¥˜
  - SGD
  - Momentum
  - Adagrad
  - Adam
  - ...
  
  ![](assets/d03_04.png 'https://ganghee-lee.tistory.com/24')
  
- ì¢‹ì€ learning rateëŠ” ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ì ì  ì¤„ì–´ë“œëŠ” í˜•íƒœë¥¼ ë³´ì¸ë‹¤.

![d03_04](assets/d03_04.jpeg 'http://aikorea.org/cs231n/assets/nn3/learningrates.jpeg')



### Activation Function

![d03_05](assets/d03_05.png 'https://miro.medium.com/max/2384/1*4ZEDRpFuCIpUjNgjDdT2Lg.png')

ì„ í˜•ì„±ì— ë¹„ì„ í˜•ì„±ì„ ê°€ë¯¸í•˜ëŠ” í•¨ìˆ˜

- Sigmoid
- Hyperbolic Tangent (tanh)
- Rectified Linear Unit (relu)
- Leaky Relu
- Parametric Relu
- ...



#### Sigmoid
- Nonlinearë¥¼ ì¶”ê°€í•´ì„œ ëª¨ë¸ì„ ë³µì¡í•˜ê²Œ ë§Œë“¤ê¸°
- Gradient vanishing
- Not zero-centered â†’ ì§€ê·¸ì¬ê·¸ ë¬¸ì œ



#### Hpyerbolic Tangent (tanh)
- Gradient vanishing
- Not zero-centered â†’ ì§€ê·¸ì¬ê·¸ ë¬¸ì œ



#### Rectified Linear Unit (relu)
- sigmoidë‚˜ tanh í•¨ìˆ˜ì™€ ë¹„êµí–ˆì„ë•Œ SGDì˜ ìˆ˜ë ´ì†ë„ê°€ ë§¤ìš° ë¹ ë¦„
- piece-wise linear
- ê³„ì‚°ì´ ê°„ë‹¨í•¨
- ë‹¨, Dead ë‰´ëŸ° ë°œìƒ ê°€ëŠ¥ì„± ì¡´ì¬ (í™œì„±í™”ë˜ì§€ ì•Šì€ ê°’ì€ ë¬´ì¡°ê±´ 0)



#### Leaky Reluì™€ Parametric Relu (p-relu)
- ê¸°ì¡´ reluë¥¼ ë³´ì™„
- ë§ˆì´ë„ˆìŠ¤ ê°’ë„ ì•½ê°„ í™œìš©ë¨



### Weight Initialization

ì´ˆê¸° ê°€ì¤‘ì¹˜ë¥¼ ì–´ë–»ê²Œ ì£¼ëŠëƒì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ê¸°ë„ í•œë‹¤.

- ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
  - ì„ í˜•ëª¨ë°ë¡­ë‹¤ ì¢‹ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤.
- ë¬´ì‘ìœ„ë¡œ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
  - ê°’ì´ ì‚¬ë¼ì§€ê±°ë‚˜ í­ë°œí•˜ëŠ” ë‘ ê°€ì§€ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.
- Xavier, He Initialization ì‚¬ìš©
  - w = np.random.randn(n_input, n_output) / sqrt(n_input/2)



### DropOut

Regularizationì˜ ì¼ì¢…ìœ¼ë¡œ hidden nodeë¥¼ ëª¨ë‘ í›ˆë ¨ì‹œí‚¤ì§€ ì•Šê³  ëœë¤í•˜ê²Œ drop out ì‹œí‚¨ë‹¤.

drop outëœ nodeì™€ ê´€ë ¨ëœ weightë“¤ì€ ëª¨ë‘ í›ˆë ¨ë˜ì§€ ì•ŠëŠ”ë‹¤.

![d03_06](assets/d03_06.png 'https://miro.medium.com/proxy/1*iWQzxhVlvadk6VAJjsgXgg.png')



### DropBlock

CNNì—ì„œ ëœë¤í•˜ê²Œ drop out ì‹œí‚¤ëŠ” ê²ƒì€ í° ì˜ë¯¸ê°€ ì—†ì„ ìˆ˜ ìˆë‹¤.

ì¸ì ‘í•œ ì˜ì—­ì„ drop ì‹œí‚¤ëŠ” ë°©ë²•

![d03_07](assets/d03_07.png 'https://norman3.github.io/papers/images/dropblock/f01.png')



### ResNet (Residual Networks)

Networksì˜ depthê°€ ëŠ˜ì–´ë‚œë‹¤ê³  ë¬´ì¡°ê±´ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ì§€ëŠ” ì•ŠëŠ”ë‹¤. (degration ë¬¸ì œ(gradient vanishing /exploding) )

residual(ì”ì°¨)ë¥¼ í•™ìŠµì‹œì¼œ ë” ê¹Šì€ networksë¥¼ ì´ì „ë³´ë‹¤ ë” ì‰½ê²Œ í•™ìŠµì‹œí‚¤ë„ë¡ ë§Œë“œëŠ” ë°©ë²•

![d03_08](assets/d03_08.png 'https://t1.daumcdn.net/cfile/tistory/991B1E4E5AE1315F38')



### Confusion Matrix

ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ì§€í‘œë¡œ ì‚¬ìš©ëœë‹¤.

![d03_09](assets/d03_09.webp 'https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnmeth.3945/MediaObjects/41592_2016_Article_BFnmeth3945_Fig1_HTML.jpg?as=webp')



### Hyper-parameter tuning

í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ê³¼ì •ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ì´ë‹¤.

ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê²½ìš° í•™ìŠµë¥ , ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°, L2 ì •ê·œí™” ê³„ìˆ˜ ë“±ì´ ìˆë‹¤.

ëŒ€í‘œì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë°©ë²•: Grid Search, Random Search

![d03_10](assets/d03_10.png 'https://nanonets.com/blog/content/images/2019/03/HPO1.png')

- ê·¸ë¦¬ë“œ íƒìƒ‰ (Grid Search)
  - ëª¨ë¸ì— ì ìš©í•˜ê³  ì‹¶ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ë¯¸ë¦¬ ì •í•´ë‘ê³  í•˜ë‚˜ì”© ì ìš©í•´ë³´ë©° ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë” ì¢‹ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ê°€ëŠ” ë°©ë²•
  - scikit-learnì˜ GridSearchCV ì´ìš©
- ëœë¤ íƒìƒ‰ (Random Search)
  - ì§€ì •ëœ ë²”ìœ„ ë‚´ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ì„ì˜ë¡œ ì ìš©í•˜ë©´ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë” ì¢‹ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ì°¾ì•„ê°€ëŠ” ë°©ë²•
  - scikit-learnì˜ RandomizedSearchCV ì´ìš©
- Baysian Optimization
  - $f(x)$ì˜ í˜•íƒœë¥¼ ëª…í™•í•˜ê²Œ ì•Œ ìˆ˜ ì—†ìœ¼ë©´ì„œ ê³„ì‚°í•˜ëŠ”ë° ì˜¤ëœ ì‹œê°„ì´ ì†Œìš”ë˜ëŠ” ê²½ìš°, ê°€ëŠ¥í•œ ì ì€ ìˆ˜ì˜ í›„ë³´ $x$ê°’ì— ëŒ€í•´ì„œ $f(x)$ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¡°ì‚¬í•˜ë©´ì„œ ìµœì í•´ $x$ë¥¼ ì°¾ì•„ê°€ëŠ” ë°©ë²•
  - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì— ì ìš©í•œë‹¤ë©´ $x$ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°, $f(x)$ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ (accuracy, precision, ...)
  - [ì°¸ê³ ](http://research.sualab.com/introduction/practice/2019/02/19/bayesian-optimization-overview-1.html)
- ì•™ìƒë¸” í•™ìŠµ (Encemble learning)
  - ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ ì—¬ëŸ¬ê°œë¥¼ ì—°ê²°í•˜ëŠ” ë°©ë²•
  - ìµœìƒì˜ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²½ìš°ê°€ ë§ë‹¤.



### ì¸ê³µì‹ ê²½ë§ í•™ìŠµ ë ˆì‹œí”¼

https://karpathy.github.io/2019/04/25/recipe/

ë²ˆì—­ê¸€: https://bit.ly/2vlTtWu



## Deep Neural Networkë¡œì˜ ë°œì „

### Convolution Neural Network

- Digit Recognition ë¬¸ì œì—ì„œ ì™„ì „ì—°ê²° ê³„ì¸µ(fully connected layer)ì„ ì´ìš©í•˜ë ¤ë©´ 3ì°¨ì› ë°ì´í„°ë¥¼ 1ì°¨ì› ë°ì´í„°ë¡œ í’€ì–´ì•¼ í•œë‹¤.

  - ì´ëŸ¬í•œ ë°©ë²•ì€ **ë°ì´í„°ì˜ í˜•ìƒì´ ë¬´ì‹œ**ë˜ì–´ ì´ë¯¸ì§€ì˜ ìœ„ì¹˜, í¬ê¸°, ê°ë„, ì¡°ëª… ë³€í™” ë“±ì— ì·¨ì•½í•˜ë‹¤.

- ë°©ë²•
  
  1. ë™ì¼í•œ ì´ë¯¸ì§€ë¥¼ ì´ë™, ì™œê³¡, ë°˜ì „, í•„í„° ì ìš© ë“±ìœ¼ë¡œ ì„ì˜ë¡œ ë³€í˜•ì‹œì¼œ ë°ì´í„°ë¥¼ ë¶€í’€ë ¤ ì‚¬ìš©
  2. ì…ë ¥ ë°ì´í„°ì˜ í˜•ìƒì„ ìœ ì§€í•  ìˆ˜ ìˆëŠ” í•©ì„±ê³±ì¸µ(Convolution Layer) ì´ìš©
  
  ![d03_11](assets/d03_11.png 'https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile21.uf.tistory.com%2Fimage%2F99A440405BC97EDC20626B')

ì°¸ê³ : https://excelsior-cjh.tistory.com/180



### Recurrent Neural Network

- ì‹œê³„ì—´ ë°ì´í„° ì¸ì‹ ë° ì˜ˆì¸¡ì— ì‚¬ìš©ëœë‹¤.

  - ìŒì„±ì¸ì‹, ë²ˆì—­, ììœ¨ì£¼í–‰, ì „ë ¥ ì˜ˆì¸¡ ë“±

- ëª¨ë“  ì…ë ¥ê³¼ ì¶œë ¥ì´ ê°ê° ë…ë¦½ì ì¸ ê²ƒì´ ì•„ë‹ˆë¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ëœë‹¤ê³  ê°€ì •

- ê´€ì‹¬ìˆëŠ” ì‹œí€€ìŠ¤ ì •ë³´ê°€ 5ê°œì˜ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§„ ë¬¸ì¥ì´ë¼ë©´, RNN ë„¤íŠ¸ì›Œí¬ëŠ” ë‹¨ì–´ë‹¹ í•˜ë‚˜ì˜ ë ˆì´ì–´ì”© 5-layer ì‹ ê²½ë§ êµ¬ì¡°ë¡œ í¼ì³ì§„ë‹¤.

  ![d03_12](assets/d03_12.png 'https://iq.opengenus.org/content/images/2018/11/rnn.png')



#### Character-level language model example

![d03_13](assets/d03_13.jpeg 'http://karpathy.github.io/assets/rnn/charseq.jpeg')

ì°¸ê³ : http://karpathy.github.io/2015/05/21/rnn-effectiveness/



#### RNNì˜ í˜•íƒœì™€ ì‚¬ë¡€

![d03_14](assets/d03_14.jpg)



#### RNN ë°œì „ë²„ì „

- Bidirectional RNN

  ![d03_15](assets/d03_15.png 'http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/bidirectional-rnn.png')

- Deep Bidirectional RNN

  ![d03_16](assets/d03_16.png 'http://www.wildml.com/wp-content/uploads/2015/09/Screen-Shot-2015-09-16-at-2.21.51-PM.png')

  ì°¸ê³ : https://buomsoo-kim.github.io/keras/2019/07/29/Easy-deep-learning-with-Keras-20.md/



#### LSTM

- ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œ (long-term dependency)

  - e.g. "ë‚˜ëŠ” í”„ë‘ìŠ¤ì—ì„œ ìëìŠµë‹ˆë‹¤. (...) ë‚˜ëŠ” ???ì–´ë¥¼ ì˜í•©ë‹ˆë‹¤."
  - (...) ì´ ë¶€ë¶„ì´ ëŠ˜ì–´ë‚  ìˆ˜ë¡ ???ì„ ì˜ˆì¸¡í•˜ê¸° ì–´ë ¤ì›Œì§„ë‹¤.

- LSTMì€ ì´ëŸ¬í•œ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ ì–´ëŠì •ë„ í•´ì†Œ ê°€ëŠ¥

  ![d03_17](assets/d03_17.png 'https://t1.daumcdn.net/cfile/tistory/271AC14F58BA963524')

ì°¸ê³ : https://firmcode.tistory.com/15



## ë”¥ëŸ¬ë‹ì„ ìœ„í•œ í™˜ê²½

### Deep Learning Framework

#### Tensorflow

- History
  - êµ¬ê¸€ ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•˜ë˜ í”„ë ˆì„ì›Œí¬ë¥¼ ê³ ë„í™”í•˜ì—¬ ì˜¤í”ˆì†ŒìŠ¤í™”
  - 2015ë…„ 11ì›” ì²« ë¦´ë¦¬ì¦ˆ
  - êµ¬ê¸€ ì„œë¹„ìŠ¤ ë° í”„ë¡œì íŠ¸ì— ë²”ìš©ì ìœ¼ë¡œ ì‚¬ìš© ì¤‘
- ì¥ì 
  - ì—°êµ¬ë¿ë§Œ ì•„ë‹ˆë¼ ì‹¤ë¬´ì—ì„œë„ í™œë°œí•˜ê²Œ ì‚¬ìš©ë˜ì–´ ê°€ì¥ ë‘í„°ìš´ ì‚¬ìš©ì ì¸µì„ ê°€ì§€ê³  ìˆë‹¤.
  - Tensorboard
- ë‹¨ì 
  - ìƒëŒ€ì ìœ¼ë¡œ ì†ë„ê°€ ëŠë¦¬ë‹¤.
  - ë²„ì „ì— ë”°ë¥¸ API ë³€í™”ê°€ ì‹¬í•˜ê³  API ì •ë¦¬ê°€ í•„ìš”
    - Tensorflow 2.0ì—ì„œ í° ë³€í™”ì¤‘



#### Pytorch

- History
  - Facebookì—ì„œ ì£¼ë¡œ ê°œë°œë¨
  - 2017ë…„ 10ì›” ì²« ë¦´ë¦¬ì¦ˆ
  - Torchë¥¼ Python ë²„ì „ìœ¼ë¡œ ìƒˆë¡œ ê°œë°œ
- ì¥ì 
  - ìµœê·¼ ì—°êµ¬ëŠ” Pytorchê°€ ì¡°ê¸ˆ ë” ë§ì€ í¸
  - ì½”ë“œê°€ ê°„ê²°í•œ í¸
- ë‹¨ì 
  - Tensorflowì— ë¹„í•´ ì‚¬ìš©ì ì¸µì´ í˜‘ì†Œí•œ í¸
  - ë³´í†µ ìŠ¤ìŠ¤ë¡œ í•™ìŠµ ì½”ë“œë¥¼ ì‘ì„±í•´ì•¼ í•œë‹¤.



#### Keras

- History
  - Francois Cholletì´ë¼ëŠ” êµ¬ê¸€ ì§ì›ì´ theanoì˜ high-level ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•´ ê°œë°œ ('15 3ì›”)
  - ì´í›„ Tensorflowê°€ ì¶œì‹œë˜ì–´ Tensorflowë„ ì§€ì› (2.0ì—ëŠ” Tensorflow ë‚´ë¶€ì— ë‚´ì¥)
- ì¥ì 
  - ì½”ë”©ì´ ë§¤ìš° ë‹¨ìˆœí•˜ê³  Pretrained model ë“±ì„ ì§€ì›
  - ë¹ ë¥´ê²Œ ëª¨ë¸ë§í•˜ì—¬ ì‹œí–‰ì°©ì˜¤ë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤.
  - Caffe, torch, tensorflow ëª¨ë¸ import ê°€ëŠ¥
- ë‹¨ì 
  - High-level ì¸í„°í˜ì´ìŠ¤ì´ê¸° ë•Œë¬¸ì— ë””í…Œì¼í•œ ì‘ì—…ì€ ì–´ë µë‹¤.
  - ìƒëŒ€ì ìœ¼ë¡œ ìµœì‹ ë²„ì „ ì‚¬ìš©ì´ ì–´ë µë‹¤.



### ë”¥ëŸ¬ë‹ í™˜ê²½ êµ¬ì„±ë°©ì•ˆ

#### ê°œì¸ ìŠ¤í„°ë””ìš© í™˜ê²½

1. ìœˆë„ìš° ë°ìŠ¤í¬íƒ‘ + VMware or Virtual Box
2. ë¦¬ëˆ…ìŠ¤ ë°ìŠ¤í¬íƒ‘
   - GTX-1060 or GTX-1080Ti
3. Cloud ì„œë¹„ìŠ¤ ì´ìš©
   - Amazon, Google, MS ë“±
   - ë¬´ë£Œ í¬ë˜ë”§ ìµœëŒ€í•œ í™œìš©
   - í¸ë¦¬í•˜ì§€ë§Œ ë°ìŠ¤í¬íƒ‘ë³´ë‹¤ ë¹„ìŒ€ ìˆ˜ ìˆìŒ
4. Google Colab
   - ì‹¤ìŠµ: https://colab.research.google.com/notebooks/welcome.ipynb?hl=ko
   - Google Drive ì—°ë™ì„ í•´ë†“ì§€ ì•Šìœ¼ë©´ ë°ì´í„°ê°€ ë‚ ì•„ê°ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜
5. ì¶”ê°€ì ì¸ í™˜ê²½ ë° ê¸°íƒ€
   - JupyterLab, Anaconda +
   - Docker

